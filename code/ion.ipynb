{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "K5gqVkr0PAet",
    "outputId": "78a4b1c6-d173-4bd5-8b48-08f8019bda43"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/gdrive') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgQFdYY-J9PC"
   },
   "outputs": [],
   "source": [
    "\n",
    "data_path = 'C:/Santosh/AI/K-Comp/Ion/Data/'\n",
    "train_signal_file = data_path + 'train_signal.npy'\n",
    "train_channels_file = data_path + 'train_channels.npy'\n",
    "test_signal_file = data_path + 'test_signal.npy'\n",
    "\n",
    "train_signal = np.load(train_signal_file)\n",
    "train_channels = np.load(train_channels_file)\n",
    "test_signal = np.load(test_signal_file)\n",
    "\n",
    "valid_signal = train_signal[:,400000:]\n",
    "valid_channels = train_channels[:,400000:]\n",
    "train_signal = train_signal[:,:400000]\n",
    "train_channels = train_channels[:,:400000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     -2.6775800939999996      -2.6967759799999995\n",
      "1     -2.6871994944881026      -2.6056200899810142\n",
      "2     -1.81228728525      -1.80535439\n",
      "3     -0.09958405574999998      -0.12528418999999996\n",
      "4     3.3522119407500006      3.30219928\n",
      "5     1.6927178065000004      1.6928120299999998\n",
      "6     -1.8023615880461925      -1.746254199981021\n",
      "7     -0.10431139079619701      -0.28071283998104035\n",
      "8     1.652365197953807      1.598213640018976\n",
      "9     3.307611075203807      3.2610364800189746\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i,\"   \",np.mean(train_signal[i]),\"    \", np.mean(train_signal[i][:10000]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     -2.6032884469524418\n",
      "0     -0.08312186995240792\n",
      "0     1.65359524\n",
      "0     -2.5381632330000006\n",
      "0     -1.8128117409524258\n",
      "1     3.2824766689999993\n",
      "1     1.649553205047574\n",
      "1     3.3342728550475904\n",
      "1     -2.6025783369524262\n",
      "1     -0.06451003300000001\n",
      "2     -2.614403360215041\n",
      "2     -2.594898185065903\n",
      "2     -2.614815458401149\n",
      "2     -2.595055447502683\n",
      "2     -2.5772216009523947\n",
      "3     -2.6058661759999993\n",
      "3     -2.6091033410000004\n",
      "3     -2.6315788\n",
      "3     -2.6564056670000005\n",
      "3     -2.602071999\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(i,\"   \", np.mean(test_signal[i][:100000]))\n",
    "    print(i,\"   \", np.mean(test_signal[i][100000:200000]))\n",
    "    print(i,\"   \", np.mean(test_signal[i][200000:300000]))\n",
    "    print(i,\"   \", np.mean(test_signal[i][300000:400000]))\n",
    "    print(i,\"   \", np.mean(test_signal[i][400000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def windowed_dataset(all_series, all_channels, window_size, batch_size, shuffle_buffer):\n",
    "    \n",
    "    all_dataset = np.zeros((end - start)*1*(window_size + 1))\n",
    "    cnt = 0\n",
    "    s = 0\n",
    "    for series in all_series:\n",
    "        \n",
    "        for i in range(start,end):\n",
    "            all_dataset[s:s + window_size] = series[i-window_size+1:i+1]\n",
    "            s += window_size\n",
    "            all_dataset[s] = all_channels[cnt][i]\n",
    "            s+=1\n",
    "\n",
    "        cnt+=1\n",
    "        break\n",
    "    #print(all_dataset)\n",
    "    series = np.array(all_dataset)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "    dataset = dataset.window(window_size + 1, shift=window_size+1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
    "    dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "    return dataset\n",
    "\n",
    "dataset = windowed_dataset(train_signal, train_channels, window_size, batch_size, shuffle_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = valid_channels[0][window_size - 1:]\n",
    "valid_input = np.zeros((100000 - window_size + 1 , window_size))\n",
    "s = 0\n",
    "for input in valid_input:\n",
    "    input = valid_signal[s:window_size]\n",
    "    s+=window_size\n",
    "y_true = (np.array(y_true).astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
    "                      input_shape=[None]),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "  tf.keras.layers.Dense(11,activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(dataset, epochs=5, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "FJ8gKpNBLcIj",
    "outputId": "0031228d-feff-4a6c-8eb9-7a829131f7ca"
   },
   "outputs": [],
   "source": [
    "\n",
    "window_size = 30\n",
    "batch_size = 100\n",
    "shuffle_buffer = 1000\n",
    "start = window_size - 1\n",
    "end = 400000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "id": "W6RpXU_oW64J",
    "outputId": "111e5cfb-6e1e-49de-832c-3c2533c7a146"
   },
   "outputs": [],
   "source": [
    "batches = [0,1,2,6]\n",
    "for k in batches:\n",
    "    print(k)\n",
    "    y_true = valid_channels[k][window_size - 1:]\n",
    "    valid_input = np.zeros((100000 - window_size + 1 , window_size))\n",
    "    s = 0\n",
    "    for input in valid_input:\n",
    "        input = valid_signal[s:window_size]\n",
    "        s+=window_size\n",
    "\n",
    "    y_pred = model.predict(valid_input)\n",
    "    y_true = (np.array(y_true).astype(int))\n",
    "    y_pred_1 = np.zeros(y_true.shape)\n",
    "    for j in range(y_pred.shape[0]):\n",
    "        maxval = 0\n",
    "        index = 0\n",
    "        for i in range(11):\n",
    "            if(y_pred[j][i] > maxval):\n",
    "                maxval = y_pred[j][i]\n",
    "                index = i\n",
    "        y_pred_1[j] = index\n",
    "    \n",
    "    print(y_true.shape)\n",
    "    y_pred_1 = np.array(y_pred_1).astype(int)\n",
    "    y_true = np.array(y_true).astype(int)\n",
    "    #print(f1_score(y_true, y_pred_1, average='macro'))\n",
    "    tp1 = 0\n",
    "    tn1 = 0\n",
    "    fp1 = 0\n",
    "    fn1 = 0\n",
    "    tp0 = 0\n",
    "    tn0 = 0\n",
    "    fp0 = 0\n",
    "    fn0 = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "\n",
    "        if(y_true[i]==1 and y_pred_1[i]==1):\n",
    "            tp1+=1\n",
    "            tn0+=1\n",
    "        if(y_true[i]==1 and y_pred_1[i]==0):\n",
    "            fn1+=1\n",
    "            fp0+=1\n",
    "        if(y_true[i]==0 and y_pred_1[i]==1):\n",
    "            fn0+=1\n",
    "            fp1+=1\n",
    "        if(y_true[i]==0 and y_pred_1[i]==0):\n",
    "            tp0+=1\n",
    "            tn1+=1\n",
    "    p1 = tp1/(tp1+fp1)\n",
    "    r1 = tp1/(tp1+fn1)\n",
    "    p0 = tp0/(tp0+fp0)\n",
    "    r0 = tp0/(tp0+fn0)\n",
    "    pre = (p1+p0)/2\n",
    "    rec = (r1+r0)/2\n",
    "    f1 = 2*(pre*rec)/(pre+rec)\n",
    "    print(f1)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
