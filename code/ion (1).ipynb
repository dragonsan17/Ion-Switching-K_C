{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqsmpyk2uYAG",
        "colab_type": "code",
        "outputId": "5d7c306e-f2e7-42d2-a5b1-cf51620b799a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axhEWXmWudOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7iDpJRsuedb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "window_size = 1\n",
        "batch_size = 5\n",
        "shuffle_buffer = 1000\n",
        "start = 300000\n",
        "end = 310000\n",
        "num_samples = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI_aCmWvujSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = '/content/gdrive/My Drive/'\n",
        "train_signal_file = data_path + 'train_signal.npy'\n",
        "train_channels_file = data_path + 'train_channels.npy'\n",
        "test_signal_file = data_path + 'test_signal.npy'\n",
        "\n",
        "train_signal = np.load(train_signal_file)\n",
        "train_channels = np.load(train_channels_file)\n",
        "test_signal = np.load(test_signal_file)\n",
        "\n",
        "valid_signal = train_signal[:,400000:]\n",
        "valid_channels = train_channels[:,400000:]\n",
        "train_signal = train_signal[:,:400000]\n",
        "train_channels = train_channels[:,:400000]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nn6DUW8furBx",
        "colab_type": "code",
        "outputId": "d4156c96-e6c8-40e7-e487-4691976b48e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "x = train_signal[:,start:end].flatten()\n",
        "y = train_channels[:,start:end].flatten()\n",
        "valid_x = valid_signal.flatten()\n",
        "valid_y = valid_channels.flatten()\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "                      input_shape=[None]),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
        "  tf.keras.layers.Dense(11,activation = 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "history = model.fit(x = x,y=y, batch_size = batch_size, shuffle = True, epochs = 5)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "20000/20000 [==============================] - 155s 8ms/step - loss: 0.4238 - acc: 0.8510\n",
            "Epoch 2/5\n",
            "20000/20000 [==============================] - 163s 8ms/step - loss: 0.3656 - acc: 0.8633\n",
            "Epoch 3/5\n",
            "20000/20000 [==============================] - 181s 9ms/step - loss: 0.3634 - acc: 0.8644\n",
            "Epoch 4/5\n",
            "20000/20000 [==============================] - 180s 9ms/step - loss: 0.3620 - acc: 0.8643\n",
            "Epoch 5/5\n",
            "20000/20000 [==============================] - 171s 9ms/step - loss: 0.3619 - acc: 0.8652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOeSTCz9h_nH",
        "colab_type": "code",
        "outputId": "a6663921-313c-453b-f6cc-1efde934a0d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "y_pred = model.predict(valid_x)\n",
        "y_true = np.array(valid_y).astype(int)\n",
        "print(y_pred[:10])\n",
        "print(y_true[:10])\n",
        "y_pred_1 = np.zeros(y_true.shape)\n",
        "for j in range(y_pred.shape[0]):\n",
        "    maxval = 0\n",
        "    index = 0\n",
        "    for i in range(11):\n",
        "        if(y_pred[j][i] > maxval):\n",
        "            maxval = y_pred[j][i]\n",
        "            index = i\n",
        "    y_pred_1[j] = index\n",
        "\n",
        "#print(y_true.shape)\n",
        "y_pred_1 = np.array(y_pred_1).astype(int)\n",
        "y_true = np.array(y_true).astype(int)\n",
        "print(f1_score(y_true, y_pred_1, average=None))\n",
        "print(f1_score(y_true, y_pred_1, average='macro'))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.9800712e-01 4.4106884e-04 6.1362999e-04 7.5754942e-04 1.7632148e-04\n",
            "  8.4876507e-07 2.8061854e-06 7.2874599e-07 1.4443453e-09 3.4915395e-09\n",
            "  6.4906303e-11]\n",
            " [9.9729037e-01 5.5985287e-04 7.9916563e-04 1.1128113e-03 2.3195057e-04\n",
            "  1.2204741e-06 4.0004184e-06 7.0793698e-07 6.8133238e-10 3.7736871e-09\n",
            "  1.3044493e-10]\n",
            " [9.9826318e-01 4.4448476e-04 5.4391072e-04 6.0925080e-04 1.3565597e-04\n",
            "  7.4597853e-07 1.9982449e-06 8.6941014e-07 4.5973088e-09 4.9591899e-09\n",
            "  3.6468113e-11]\n",
            " [9.9824834e-01 4.2963095e-04 5.4976717e-04 6.2515563e-04 1.4343087e-04\n",
            "  7.4663149e-07 2.1501828e-06 8.2838454e-07 3.4082823e-09 4.3591433e-09\n",
            "  4.0837451e-11]\n",
            " [9.9813336e-01 4.2681448e-04 5.8105052e-04 6.9223711e-04 1.6255531e-04\n",
            "  7.9116143e-07 2.5265886e-06 7.5841689e-07 1.9480932e-09 3.6568433e-09\n",
            "  5.3557977e-11]\n",
            " [1.4274445e-01 8.2306439e-01 4.6908688e-03 2.8205080e-02 1.2587378e-03\n",
            "  3.6369627e-05 3.1173876e-08 9.1769675e-10 4.0972989e-08 8.9332204e-09\n",
            "  3.4219914e-12]\n",
            " [9.9787998e-01 7.0585345e-04 6.0734153e-04 6.8788271e-04 1.1553947e-04\n",
            "  9.3260348e-07 1.4704943e-06 1.0367168e-06 1.9155260e-08 1.0259391e-08\n",
            "  2.1354701e-11]\n",
            " [9.9804258e-01 4.3646115e-04 6.0449768e-04 7.3944154e-04 1.7273727e-04\n",
            "  8.3212251e-07 2.7326405e-06 7.3511842e-07 1.5514509e-09 3.5179486e-09\n",
            "  6.1766592e-11]\n",
            " [9.9792922e-01 6.7774282e-04 5.9873634e-04 6.7514786e-04 1.1577239e-04\n",
            "  9.1226366e-07 1.4945399e-06 1.0320654e-06 1.7821625e-08 9.9067865e-09\n",
            "  2.2184372e-11]\n",
            " [9.9713564e-01 1.1259426e-03 7.3120900e-04 8.8283408e-04 1.2091880e-04\n",
            "  1.2016892e-06 1.2667891e-06 1.0224780e-06 3.2859607e-08 1.2544580e-08\n",
            "  1.3617900e-11]]\n",
            "[0 0 0 0 0 0 0 0 0 0]\n",
            "[0.991445   0.97638724 0.93554242 0.89901457 0.71273675 0.49140921\n",
            " 0.35041689 0.39386289 0.82755491 0.87309989 0.85718538]\n",
            "0.7553322871518483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4Fsnfs7ulBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def windowed_dataset(all_series, all_channels, window_size, batch_size, shuffle_buffer):\n",
        "    \n",
        "    all_dataset = np.zeros((end - start)*10*(window_size + 1))\n",
        "    cnt = 0\n",
        "    s = 0\n",
        "    for series in all_series:\n",
        "        for i in range(start,end):\n",
        "            all_dataset[s:s + window_size] = series[i-window_size+1:i+1]\n",
        "            s += window_size\n",
        "            all_dataset[s] = all_channels[cnt][i]\n",
        "            s+=1\n",
        "        cnt+=1\n",
        "    #print(all_dataset)\n",
        "    series = np.array(all_dataset)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "    dataset = dataset.window(window_size + 1, shift=window_size+1, drop_remainder=True)\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
        "    dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n",
        "    dataset = dataset.batch(batch_size).prefetch(1)\n",
        "    return dataset\n",
        "\n",
        "dataset = windowed_dataset(train_signal, train_channels, window_size, batch_size, shuffle_buffer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI9PtnPhorBc",
        "colab_type": "code",
        "outputId": "7297bd15-eea0-42f8-b5b5-109e63e556a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "models = []\n",
        "\n",
        "for k in range (10):\n",
        "  x = train_signal[k].flatten()\n",
        "  y = train_channels[k].flatten()\n",
        "  valid_x = valid_signal[k].flatten()\n",
        "  valid_y = valid_channels[k].flatten()\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "                        input_shape=[None]),\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
        "    tf.keras.layers.Dense(11,activation = 'softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(loss='sparse_categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['acc'])\n",
        "  \n",
        "  if(k==9 or k==4):\n",
        "    history = model.fit(x = x,y=y, batch_size = batch_size, shuffle = True, epochs = 2)\n",
        "  else:\n",
        "    history = model.fit(x = x,y=y, batch_size = batch_size, shuffle = True, epochs = 30, steps_per_epoch=500)\n",
        "\n",
        "  models.append(model)\n",
        "  y_pred = model.predict(valid_x)\n",
        "  y_true = np.array(valid_y).astype(int)\n",
        "  print(y_pred[:10])\n",
        "  print(y_true[:10])\n",
        "  y_pred_1 = np.zeros(y_true.shape)\n",
        "  for j in range(y_pred.shape[0]):\n",
        "      maxval = 0\n",
        "      index = 0\n",
        "      for i in range(11):\n",
        "          if(y_pred[j][i] > maxval):\n",
        "              maxval = y_pred[j][i]\n",
        "              index = i\n",
        "      y_pred_1[j] = index\n",
        "\n",
        "  #print(y_true.shape)\n",
        "  y_pred_1 = np.array(y_pred_1).astype(int)\n",
        "  y_true = np.array(y_true).astype(int)\n",
        "  print(f1_score(y_true, y_pred_1, average=None))\n",
        "  print(f1_score(y_true, y_pred_1, average='macro'))\n",
        "  print(k,\"   done\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.3021 - acc: 0.9628\n",
            "Epoch 2/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0840 - acc: 0.9648\n",
            "Epoch 3/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0455 - acc: 0.9804\n",
            "Epoch 4/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0136 - acc: 0.9984\n",
            "Epoch 5/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0114 - acc: 0.9972\n",
            "Epoch 6/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0141 - acc: 0.9960\n",
            "Epoch 7/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0079 - acc: 0.9976\n",
            "Epoch 8/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0077 - acc: 0.9976\n",
            "Epoch 9/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0103 - acc: 0.9972\n",
            "Epoch 10/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0073 - acc: 0.9980\n",
            "Epoch 11/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0101 - acc: 0.9960\n",
            "Epoch 12/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0143 - acc: 0.9952\n",
            "Epoch 13/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0044 - acc: 0.9984\n",
            "Epoch 14/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0069 - acc: 0.9976\n",
            "Epoch 15/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0105 - acc: 0.9960\n",
            "Epoch 16/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0035 - acc: 0.9992\n",
            "Epoch 17/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0125 - acc: 0.9964\n",
            "Epoch 18/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0061 - acc: 0.9968\n",
            "Epoch 19/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0044 - acc: 0.9992\n",
            "Epoch 20/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0086 - acc: 0.9968\n",
            "Epoch 21/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0053 - acc: 0.9984\n",
            "Epoch 22/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0019 - acc: 0.9996\n",
            "Epoch 23/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0074 - acc: 0.9968\n",
            "Epoch 24/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0085 - acc: 0.9976\n",
            "Epoch 25/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0072 - acc: 0.9968\n",
            "Epoch 26/30\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0091 - acc: 0.9976\n",
            "Epoch 27/30\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0074 - acc: 0.9968\n",
            "Epoch 28/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0026 - acc: 0.9992\n",
            "Epoch 29/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0093 - acc: 0.9968\n",
            "Epoch 30/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0095 - acc: 0.9960\n",
            "[[9.99991894e-01 8.11232167e-06 1.95967331e-09 1.29630306e-09\n",
            "  1.46619428e-09 3.38415251e-09 3.01932324e-09 2.10873585e-09\n",
            "  1.61301683e-09 1.77311421e-09 1.78301696e-09]\n",
            " [9.99993205e-01 6.83578492e-06 1.62494773e-09 1.05739972e-09\n",
            "  1.21419852e-09 2.79647150e-09 2.51590437e-09 1.74887949e-09\n",
            "  1.34437472e-09 1.46429013e-09 1.47973200e-09]\n",
            " [9.99988317e-01 1.16287592e-05 2.82371770e-09 1.91952476e-09\n",
            "  2.11621054e-09 4.90516650e-09 4.31837055e-09 3.04377057e-09\n",
            "  2.30280595e-09 2.56795629e-09 2.56430988e-09]\n",
            " [9.99989510e-01 1.04938645e-05 2.55203170e-09 1.72269221e-09\n",
            "  1.91188665e-09 4.42637704e-09 3.91002830e-09 2.74902390e-09\n",
            "  2.08636664e-09 2.31829467e-09 2.31883424e-09]\n",
            " [9.99991179e-01 8.81245523e-06 2.13747731e-09 1.42384515e-09\n",
            "  1.60000524e-09 3.69671116e-09 3.28671912e-09 2.30052977e-09\n",
            "  1.75533588e-09 1.93690020e-09 1.94395078e-09]\n",
            " [9.60919619e-01 3.90661806e-02 1.48904360e-06 1.15145826e-06\n",
            "  1.10903329e-06 2.68773488e-06 2.22729045e-06 1.73579372e-06\n",
            "  1.19108711e-06 1.30035949e-06 1.33901688e-06]\n",
            " [9.99978781e-01 2.12660561e-05 4.95697972e-09 3.48369511e-09\n",
            "  3.71892805e-09 8.67580940e-09 7.52075646e-09 5.37337641e-09\n",
            "  3.99336741e-09 4.52279192e-09 4.48789494e-09]\n",
            " [9.99991775e-01 8.26836185e-06 1.99960914e-09 1.32491440e-09\n",
            "  1.49625323e-09 3.45432949e-09 3.07937853e-09 2.15177920e-09\n",
            "  1.64499980e-09 1.80991411e-09 1.81917215e-09]\n",
            " [9.99979496e-01 2.04667358e-05 4.78915707e-09 3.35972294e-09\n",
            "  3.59293861e-09 8.37861425e-09 7.26901828e-09 5.18934717e-09\n",
            "  3.86079702e-09 4.36928538e-09 4.33675584e-09]\n",
            " [9.99969244e-01 3.07437404e-05 6.85879797e-09 4.89604357e-09\n",
            "  5.14588727e-09 1.20483401e-08 1.03717870e-08 7.46566009e-09\n",
            "  5.49260415e-09 6.25953156e-09 6.19915097e-09]]\n",
            "[0 0 0 0 0 0 0 0 0 0]\n",
            "[0.99909243 0.95402893]\n",
            "0.976560677526837\n",
            "0    done\n",
            "Epoch 1/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.2906 - acc: 0.9608\n",
            "Epoch 2/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0878 - acc: 0.9644\n",
            "Epoch 3/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0419 - acc: 0.9816\n",
            "Epoch 4/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0183 - acc: 0.9960\n",
            "Epoch 5/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0159 - acc: 0.9944\n",
            "Epoch 6/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0139 - acc: 0.9944\n",
            "Epoch 7/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0066 - acc: 0.9988\n",
            "Epoch 8/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0127 - acc: 0.9956\n",
            "Epoch 9/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0125 - acc: 0.9968\n",
            "Epoch 10/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0112 - acc: 0.9964\n",
            "Epoch 11/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0102 - acc: 0.9964\n",
            "Epoch 12/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0080 - acc: 0.9976\n",
            "Epoch 13/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0079 - acc: 0.9968\n",
            "Epoch 14/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0088 - acc: 0.9976\n",
            "Epoch 15/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0082 - acc: 0.9968\n",
            "Epoch 16/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0116 - acc: 0.9968\n",
            "Epoch 17/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0113 - acc: 0.9960\n",
            "Epoch 18/30\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0091 - acc: 0.9976\n",
            "Epoch 19/30\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0091 - acc: 0.9960\n",
            "Epoch 20/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0154 - acc: 0.9956\n",
            "Epoch 21/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0093 - acc: 0.9964\n",
            "Epoch 22/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0146 - acc: 0.9956\n",
            "Epoch 23/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0083 - acc: 0.9976\n",
            "Epoch 24/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0143 - acc: 0.9960\n",
            "Epoch 25/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0075 - acc: 0.9972\n",
            "Epoch 26/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0088 - acc: 0.9972\n",
            "Epoch 27/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0075 - acc: 0.9976\n",
            "Epoch 28/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0188 - acc: 0.9952\n",
            "Epoch 29/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0090 - acc: 0.9968\n",
            "Epoch 30/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0086 - acc: 0.9964\n",
            "[[9.9996603e-01 3.3957589e-05 2.8504024e-09 3.2291714e-09 2.7462919e-09\n",
            "  2.2583011e-09 2.3518836e-09 1.9364970e-09 2.6589608e-09 2.1908255e-09\n",
            "  1.9522135e-09]\n",
            " [9.9998057e-01 1.9463141e-05 1.7309371e-09 1.9711035e-09 1.6438586e-09\n",
            "  1.3844235e-09 1.4198274e-09 1.1882711e-09 1.6296542e-09 1.3209430e-09\n",
            "  1.1472633e-09]\n",
            " [9.9995410e-01 4.5938148e-05 3.7108723e-09 4.1931636e-09 3.5996242e-09\n",
            "  2.9271381e-09 3.0719063e-09 2.5100781e-09 3.4471110e-09 2.8624685e-09\n",
            "  2.5818208e-09]\n",
            " [9.9960130e-01 3.9859433e-04 2.2267823e-08 2.4726447e-08 2.2337076e-08\n",
            "  1.7202481e-08 1.8884188e-08 1.4809426e-08 2.0259700e-08 1.7550104e-08\n",
            "  1.6870496e-08]\n",
            " [9.9982053e-01 1.7947816e-04 1.1674021e-08 1.3046707e-08 1.1595906e-08\n",
            "  9.0712273e-09 9.8112363e-09 7.7951965e-09 1.0687336e-08 9.1347925e-09\n",
            "  8.6094429e-09]\n",
            " [9.9996853e-01 3.1463722e-05 2.6648976e-09 3.0210381e-09 2.5629048e-09\n",
            "  2.1138289e-09 2.1970159e-09 1.8126911e-09 2.4887474e-09 2.0463289e-09\n",
            "  1.8175518e-09]\n",
            " [9.9996483e-01 3.5175719e-05 2.9401286e-09 3.3298044e-09 2.8350708e-09\n",
            "  2.3281368e-09 2.4268338e-09 1.9963582e-09 2.7412490e-09 2.2607638e-09\n",
            "  2.0174955e-09]\n",
            " [9.9992347e-01 7.6537333e-05 5.7436749e-09 6.4630243e-09 5.6278999e-09\n",
            "  4.5014055e-09 4.7814410e-09 3.8620311e-09 5.3025255e-09 4.4558415e-09\n",
            "  4.0931392e-09]\n",
            " [9.9066216e-01 9.3359975e-03 2.5372930e-07 2.7386659e-07 2.5912948e-07\n",
            "  1.9456773e-07 2.2291860e-07 1.6853680e-07 2.2750702e-07 2.0440950e-07\n",
            "  2.0679201e-07]\n",
            " [9.9994814e-01 5.1819756e-05 4.1177186e-09 4.6482209e-09 4.0043653e-09\n",
            "  3.2427663e-09 3.4131875e-09 2.7809530e-09 3.8190979e-09 3.1807004e-09\n",
            "  2.8819322e-09]]\n",
            "[0 0 0 0 0 0 0 0 0 0]\n",
            "[0.99877409 0.97655228]\n",
            "0.9876631850281054\n",
            "1    done\n",
            "Epoch 1/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.6358 - acc: 0.7996\n",
            "Epoch 2/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0865 - acc: 0.9896\n",
            "Epoch 3/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0349 - acc: 0.9920\n",
            "Epoch 4/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0238 - acc: 0.9928\n",
            "Epoch 5/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0227 - acc: 0.9916\n",
            "Epoch 6/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0143 - acc: 0.9948\n",
            "Epoch 7/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0215 - acc: 0.9916\n",
            "Epoch 8/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0218 - acc: 0.9916\n",
            "Epoch 9/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0159 - acc: 0.9956\n",
            "Epoch 10/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0126 - acc: 0.9964\n",
            "Epoch 11/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0302 - acc: 0.9920\n",
            "Epoch 12/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0227 - acc: 0.9928\n",
            "Epoch 13/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0162 - acc: 0.9952\n",
            "Epoch 14/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0086 - acc: 0.9968\n",
            "Epoch 15/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0213 - acc: 0.9912\n",
            "Epoch 16/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0226 - acc: 0.9928\n",
            "Epoch 17/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0241 - acc: 0.9916\n",
            "Epoch 18/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0198 - acc: 0.9912\n",
            "Epoch 19/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0202 - acc: 0.9940\n",
            "Epoch 20/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0190 - acc: 0.9948\n",
            "Epoch 21/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0135 - acc: 0.9956\n",
            "Epoch 22/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0200 - acc: 0.9936\n",
            "Epoch 23/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0218 - acc: 0.9932\n",
            "Epoch 24/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0162 - acc: 0.9948\n",
            "Epoch 25/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0202 - acc: 0.9924\n",
            "Epoch 26/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0291 - acc: 0.9896\n",
            "Epoch 27/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0182 - acc: 0.9932\n",
            "Epoch 28/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0189 - acc: 0.9932\n",
            "Epoch 29/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0174 - acc: 0.9948\n",
            "Epoch 30/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0125 - acc: 0.9956\n",
            "[[4.3723159e-04 9.9956173e-01 1.3107044e-07 1.3108682e-07 1.3915049e-07\n",
            "  1.2764394e-07 1.5233232e-07 9.4597105e-08 1.3592927e-07 1.0964731e-07\n",
            "  1.3248032e-07]\n",
            " [7.0370043e-05 9.9992931e-01 3.6935173e-08 3.9990564e-08 3.9712894e-08\n",
            "  3.8382773e-08 3.8393317e-08 2.7842987e-08 3.9713655e-08 3.3974977e-08\n",
            "  4.2543999e-08]\n",
            " [1.3609153e-04 9.9986339e-01 5.7958243e-08 6.0607789e-08 6.2185578e-08\n",
            "  5.8698731e-08 6.3283757e-08 4.2832024e-08 6.1356729e-08 5.1160072e-08\n",
            "  6.2867493e-08]\n",
            " [1.0893383e-04 9.9989057e-01 4.9633943e-08 5.2469108e-08 5.3315507e-08\n",
            "  5.0689785e-08 5.3375949e-08 3.6902545e-08 5.2805333e-08 4.4382585e-08\n",
            "  5.4837795e-08]\n",
            " [4.8834288e-05 9.9995077e-01 2.9362219e-08 3.2535315e-08 3.1543330e-08\n",
            "  3.0999850e-08 2.9518549e-08 2.2448178e-08 3.1877310e-08 2.7749687e-08\n",
            "  3.5249318e-08]\n",
            " [2.0701652e-03 9.9792671e-01 3.6098274e-07 3.4891781e-07 3.7649338e-07\n",
            "  3.3726482e-07 4.4203227e-07 2.5617069e-07 3.6928921e-07 2.9008265e-07\n",
            "  3.4988815e-07]\n",
            " [5.9698883e-05 9.9993992e-01 3.3220534e-08 3.6331041e-08 3.5712564e-08\n",
            "  3.4763399e-08 3.4038187e-08 2.5193586e-08 3.5872105e-08 3.0919267e-08\n",
            "  3.8952919e-08]\n",
            " [3.6412497e-05 9.9996340e-01 2.4932733e-08 2.8218560e-08 2.6731168e-08\n",
            "  2.6693570e-08 2.4300320e-08 1.9323529e-08 2.7292316e-08 2.4150475e-08\n",
            "  3.1106385e-08]\n",
            " [7.8018089e-03 9.9219149e-01 7.8361870e-07 7.4737409e-07 8.0668116e-07\n",
            "  7.1256204e-07 9.8612850e-07 5.5265326e-07 7.9950257e-07 6.2152600e-07\n",
            "  7.5637433e-07]\n",
            " [1.4161895e-04 9.9985778e-01 5.9598207e-08 6.2207526e-08 6.3929420e-08\n",
            "  6.0271532e-08 6.5243306e-08 4.3999062e-08 6.3039089e-08 5.2491213e-08\n",
            "  6.4445828e-08]]\n",
            "[1 1 1 1 1 1 1 1 1 1]\n",
            "[0.98923041 0.99632501]\n",
            "0.9927777075663176\n",
            "2    done\n",
            "Epoch 1/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.6432 - acc: 0.8988\n",
            "Epoch 2/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0875 - acc: 0.9664\n",
            "Epoch 3/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0900 - acc: 0.9716\n",
            "Epoch 4/30\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.0571 - acc: 0.9812\n",
            "Epoch 5/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0592 - acc: 0.9800\n",
            "Epoch 6/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0589 - acc: 0.9780\n",
            "Epoch 7/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0524 - acc: 0.9808\n",
            "Epoch 8/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0441 - acc: 0.9852\n",
            "Epoch 9/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0518 - acc: 0.9836\n",
            "Epoch 10/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0611 - acc: 0.9796\n",
            "Epoch 11/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0516 - acc: 0.9828\n",
            "Epoch 12/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0527 - acc: 0.9780\n",
            "Epoch 13/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0607 - acc: 0.9780\n",
            "Epoch 14/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0573 - acc: 0.9800\n",
            "Epoch 15/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0485 - acc: 0.9844\n",
            "Epoch 16/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0554 - acc: 0.9832\n",
            "Epoch 17/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0655 - acc: 0.9748\n",
            "Epoch 18/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0526 - acc: 0.9840\n",
            "Epoch 19/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0525 - acc: 0.9828\n",
            "Epoch 20/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0447 - acc: 0.9860\n",
            "Epoch 21/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0518 - acc: 0.9828\n",
            "Epoch 22/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0607 - acc: 0.9788\n",
            "Epoch 23/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0573 - acc: 0.9796\n",
            "Epoch 24/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0484 - acc: 0.9836\n",
            "Epoch 25/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0595 - acc: 0.9772\n",
            "Epoch 26/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0544 - acc: 0.9800\n",
            "Epoch 27/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0469 - acc: 0.9816\n",
            "Epoch 28/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0468 - acc: 0.9804\n",
            "Epoch 29/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0495 - acc: 0.9812\n",
            "Epoch 30/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0411 - acc: 0.9860\n",
            "[[6.7965470e-06 8.4356043e-07 1.2565900e-04 9.9986041e-01 9.2672974e-07\n",
            "  8.2613059e-07 8.4330952e-07 9.2457577e-07 1.0437742e-06 7.7977683e-07\n",
            "  9.5826056e-07]\n",
            " [2.3580055e-06 2.2731725e-05 9.3497574e-02 9.0647691e-01 5.3907119e-08\n",
            "  7.0054874e-08 6.7472065e-08 4.8691735e-08 7.7558028e-08 6.1418547e-08\n",
            "  8.1047283e-08]\n",
            " [1.8152861e-06 5.9244320e-07 1.6172518e-04 9.9983346e-01 3.3508528e-07\n",
            "  2.8633903e-07 3.5069678e-07 3.2070074e-07 3.4887447e-07 3.1985709e-07\n",
            "  3.9055544e-07]\n",
            " [3.5693843e-06 6.9392269e-07 1.3282904e-04 9.9985898e-01 5.6809046e-07\n",
            "  4.9194153e-07 5.5109604e-07 5.5302132e-07 6.1079066e-07 5.0545998e-07\n",
            "  6.1904154e-07]\n",
            " [5.0979725e-06 7.7031240e-07 1.2749138e-04 9.9986148e-01 7.4710164e-07\n",
            "  6.5660487e-07 6.9875693e-07 7.3681076e-07 8.2375948e-07 6.4346614e-07\n",
            "  7.8944367e-07]\n",
            " [1.3959431e-06 5.7935080e-07 1.9344357e-04 9.9980265e-01 2.6550174e-07\n",
            "  2.2881001e-07 2.8809251e-07 2.5419249e-07 2.7673923e-07 2.6223492e-07\n",
            "  3.2021043e-07]\n",
            " [1.4769169e-06 5.7969203e-07 1.8425529e-04 9.9981171e-01 2.8032181e-07\n",
            "  2.4080754e-07 3.0159273e-07 2.6818228e-07 2.9176502e-07 2.7463972e-07\n",
            "  3.3528957e-07]\n",
            " [9.8806083e-07 7.6963028e-07 4.9223023e-04 9.9950492e-01 1.3433277e-07\n",
            "  1.2806464e-07 1.6008798e-07 1.3309264e-07 1.4954951e-07 1.4619334e-07\n",
            "  1.8156754e-07]\n",
            " [1.2817678e-06 5.8312060e-07 2.1185505e-04 9.9978441e-01 2.4247558e-07\n",
            "  2.1047747e-07 2.6687428e-07 2.3265426e-07 2.5376158e-07 2.4277455e-07\n",
            "  2.9665298e-07]\n",
            " [1.4242926e-06 5.7926059e-07 1.8995107e-04 9.9980611e-01 2.7080480e-07\n",
            "  2.3308596e-07 2.9293577e-07 2.5918709e-07 2.8209453e-07 2.6668366e-07\n",
            "  3.2561289e-07]]\n",
            "[3 3 3 3 3 3 3 3 3 3]\n",
            "[0.96369034 0.9766913  0.98164506 0.98754265]\n",
            "0.9773923371683646\n",
            "3    done\n",
            "Epoch 1/2\n",
            "80000/80000 [==============================] - 572s 7ms/step - loss: 0.3393 - acc: 0.8647\n",
            "Epoch 2/2\n",
            "80000/80000 [==============================] - 575s 7ms/step - loss: 0.3219 - acc: 0.8711\n",
            "[[3.3863498e-10 5.4909872e-08 4.0876455e-11 2.1733882e-08 3.1773880e-08\n",
            "  1.6233528e-06 1.6195967e-06 4.6280331e-07 9.2853579e-06 1.1044670e-02\n",
            "  9.8894227e-01]\n",
            " [5.2342808e-10 5.2049078e-08 9.8607504e-11 4.5929642e-08 7.8410956e-08\n",
            "  3.8350481e-06 3.8928533e-06 1.2796088e-06 3.1577812e-05 3.2036494e-02\n",
            "  9.6792275e-01]\n",
            " [3.1260416e-10 5.7655342e-08 3.2693202e-11 1.7868425e-08 2.5483491e-08\n",
            "  1.3150294e-06 1.2962306e-06 3.5745677e-07 6.8242193e-06 8.4170643e-03\n",
            "  9.9157310e-01]\n",
            " [4.1100864e-10 5.2466088e-08 6.2577776e-11 3.1312027e-08 4.8947634e-08\n",
            "  2.4511414e-06 2.4769263e-06 7.5708220e-07 1.6756119e-05 1.8506140e-02\n",
            "  9.8147124e-01]\n",
            " [1.7236941e-09 4.4582791e-08 1.3508311e-09 3.1070613e-07 8.8552468e-07\n",
            "  3.4116460e-05 3.4316490e-05 1.9169438e-05 1.0072633e-03 5.3515869e-01\n",
            "  4.6374518e-01]\n",
            " [1.7265590e-09 4.4145207e-08 1.3834817e-09 3.1440325e-07 8.9881752e-07\n",
            "  3.4471319e-05 3.4678327e-05 1.9518615e-05 1.0354926e-03 5.4514229e-01\n",
            "  4.5373228e-01]\n",
            " [1.2903619e-09 2.0517698e-08 7.4919146e-09 6.3846039e-07 1.8902783e-06\n",
            "  3.3864362e-05 3.1219515e-05 4.0767074e-05 5.0778938e-03 9.5356691e-01\n",
            "  4.1246753e-02]\n",
            " [1.2881189e-09 2.0393932e-08 7.8847116e-09 6.5880312e-07 1.9491640e-06\n",
            "  3.3589862e-05 3.0696359e-05 4.1462121e-05 5.3120381e-03 9.5634794e-01\n",
            "  3.8231514e-02]\n",
            " [3.7382275e-10 5.3257903e-08 5.1396637e-11 2.6474227e-08 4.0022535e-08\n",
            "  2.0232956e-06 2.0352595e-06 6.0301164e-07 1.2747649e-05 1.4580705e-02\n",
            "  9.8540175e-01]\n",
            " [1.4792121e-09 5.2574347e-08 7.1265155e-10 2.1305065e-07 5.4815973e-07\n",
            "  2.3148077e-05 2.3249515e-05 1.0962475e-05 4.5966438e-04 3.0011126e-01\n",
            "  6.9937086e-01]]\n",
            "[10 10 10 10  9 10  9  9 10  9]\n",
            "[0.         0.78810409 0.81810833 0.83098054 0.864568   0.87289786\n",
            " 0.87648659 0.87862031 0.87038988 0.85561088]\n",
            "0.7655766480742956\n",
            "4    done\n",
            "Epoch 1/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 1.0352 - acc: 0.6392\n",
            "Epoch 2/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.2207 - acc: 0.9552\n",
            "Epoch 3/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1151 - acc: 0.9664\n",
            "Epoch 4/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1040 - acc: 0.9656\n",
            "Epoch 5/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1078 - acc: 0.9620\n",
            "Epoch 6/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1002 - acc: 0.9656\n",
            "Epoch 7/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1065 - acc: 0.9604\n",
            "Epoch 8/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1011 - acc: 0.9632\n",
            "Epoch 9/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0885 - acc: 0.9696\n",
            "Epoch 10/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0843 - acc: 0.9724\n",
            "Epoch 11/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0903 - acc: 0.9656\n",
            "Epoch 12/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0907 - acc: 0.9664\n",
            "Epoch 13/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1052 - acc: 0.9604\n",
            "Epoch 14/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0871 - acc: 0.9700\n",
            "Epoch 15/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0783 - acc: 0.9700\n",
            "Epoch 16/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0860 - acc: 0.9672\n",
            "Epoch 17/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0850 - acc: 0.9688\n",
            "Epoch 18/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0875 - acc: 0.9660\n",
            "Epoch 19/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0739 - acc: 0.9720\n",
            "Epoch 20/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0780 - acc: 0.9720\n",
            "Epoch 21/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0907 - acc: 0.9652\n",
            "Epoch 22/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0909 - acc: 0.9632\n",
            "Epoch 23/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1009 - acc: 0.9724\n",
            "Epoch 24/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0895 - acc: 0.9664\n",
            "Epoch 25/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0865 - acc: 0.9720\n",
            "Epoch 26/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1040 - acc: 0.9624\n",
            "Epoch 27/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0849 - acc: 0.9704\n",
            "Epoch 28/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0791 - acc: 0.9716\n",
            "Epoch 29/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0934 - acc: 0.9636\n",
            "Epoch 30/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0814 - acc: 0.9676\n",
            "[[2.6060766e-06 8.4107171e-07 3.6394831e-06 8.2225188e-06 2.0059717e-03\n",
            "  9.9797398e-01 7.7611685e-07 1.0225280e-06 8.7092565e-07 1.2558277e-06\n",
            "  8.5444049e-07]\n",
            " [2.4438757e-06 7.8882545e-07 3.2895166e-06 6.7088858e-06 1.5309531e-03\n",
            "  9.9845171e-01 6.6880955e-07 8.9688166e-07 7.6041755e-07 1.1100980e-06\n",
            "  7.5480222e-07]\n",
            " [3.4136319e-06 1.2367695e-06 5.9832710e-06 1.8739629e-05 5.7808394e-03\n",
            "  9.9418288e-01 1.1467432e-06 1.4684704e-06 1.2472377e-06 1.7921145e-06\n",
            "  1.2100940e-06]\n",
            " [5.0471831e-06 2.3590787e-06 1.3352824e-05 6.3170264e-05 2.6736127e-02\n",
            "  9.7317040e-01 1.6669752e-06 2.0817110e-06 1.7282005e-06 2.5442007e-06\n",
            "  1.6962778e-06]\n",
            " [2.9519977e-06 9.9383715e-07 4.5321344e-06 1.2021056e-05 3.2813244e-03\n",
            "  9.9669242e-01 9.5322321e-07 1.2358034e-06 1.0538188e-06 1.5105769e-06\n",
            "  1.0247750e-06]\n",
            " [2.6516288e-06 8.5907334e-07 3.7460175e-06 8.6690625e-06 2.1497328e-03\n",
            "  9.9782938e-01 8.0197555e-07 1.0535226e-06 8.9784550e-07 1.2925067e-06\n",
            "  8.7917988e-07]\n",
            " [2.6958223e-06 8.7730365e-07 3.8528024e-06 9.1166658e-06 2.2955590e-03\n",
            "  9.9768281e-01 8.2612337e-07 1.0825519e-06 9.2294931e-07 1.3269978e-06\n",
            "  9.0236495e-07]\n",
            " [3.5090075e-06 1.2912907e-06 6.3169305e-06 2.0389161e-05 6.4334269e-03\n",
            "  9.9352795e-01 1.1827929e-06 1.5115994e-06 1.2824006e-06 1.8445553e-06\n",
            "  1.2443567e-06]\n",
            " [6.9724861e-06 6.4237843e-06 4.9247341e-05 5.3861272e-04 4.3251151e-01\n",
            "  5.6687516e-01 2.1822977e-06 2.5760141e-06 2.0159373e-06 3.2220239e-06\n",
            "  2.1092940e-06]\n",
            " [2.4257220e-06 7.8621986e-07 3.2513003e-06 6.5253657e-06 1.4742392e-03\n",
            "  9.9850863e-01 6.5239243e-07 8.7883660e-07 7.4429778e-07 1.0900696e-06\n",
            "  7.4074876e-07]]\n",
            "[5 5 5 5 5 5 5 5 5 5]\n",
            "[0.93186004 0.9564022  0.96652216 0.96399711 0.9658555  0.9708814 ]\n",
            "0.9592530668955505\n",
            "5    done\n",
            "Epoch 1/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.6616 - acc: 0.7820\n",
            "Epoch 2/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0931 - acc: 0.9900\n",
            "Epoch 3/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0291 - acc: 0.9952\n",
            "Epoch 4/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0281 - acc: 0.9936\n",
            "Epoch 5/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0299 - acc: 0.9896\n",
            "Epoch 6/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0139 - acc: 0.9968\n",
            "Epoch 7/30\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.0238 - acc: 0.9908\n",
            "Epoch 8/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0263 - acc: 0.9900\n",
            "Epoch 9/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0156 - acc: 0.9952\n",
            "Epoch 10/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0217 - acc: 0.9940\n",
            "Epoch 11/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0177 - acc: 0.9924\n",
            "Epoch 12/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0215 - acc: 0.9912\n",
            "Epoch 13/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0241 - acc: 0.9932\n",
            "Epoch 14/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0154 - acc: 0.9932\n",
            "Epoch 15/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0237 - acc: 0.9912\n",
            "Epoch 16/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0255 - acc: 0.9904\n",
            "Epoch 17/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0251 - acc: 0.9904\n",
            "Epoch 18/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0169 - acc: 0.9956\n",
            "Epoch 19/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0162 - acc: 0.9932\n",
            "Epoch 20/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0205 - acc: 0.9924\n",
            "Epoch 21/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0236 - acc: 0.9904\n",
            "Epoch 22/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0172 - acc: 0.9936\n",
            "Epoch 23/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0115 - acc: 0.9960\n",
            "Epoch 24/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0127 - acc: 0.9968\n",
            "Epoch 25/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0175 - acc: 0.9944\n",
            "Epoch 26/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0144 - acc: 0.9960\n",
            "Epoch 27/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0150 - acc: 0.9948\n",
            "Epoch 28/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0241 - acc: 0.9908\n",
            "Epoch 29/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0245 - acc: 0.9928\n",
            "Epoch 30/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0132 - acc: 0.9956\n",
            "[[3.06841393e-05 9.99969363e-01 1.25694601e-08 1.21526833e-08\n",
            "  9.38311384e-09 8.32924663e-09 1.15349792e-08 1.15153043e-08\n",
            "  1.48110360e-08 9.93981075e-09 8.67825989e-09]\n",
            " [5.77613719e-05 9.99942064e-01 2.10632454e-08 2.04134452e-08\n",
            "  1.58557345e-08 1.43270844e-08 2.00766586e-08 2.00032346e-08\n",
            "  2.45145504e-08 1.71683183e-08 1.51724446e-08]\n",
            " [4.33530891e-04 9.99565661e-01 9.92491209e-08 9.33238056e-08\n",
            "  7.09871273e-08 7.22345419e-08 9.50621342e-08 9.54986632e-08\n",
            "  1.09064970e-07 8.48560120e-08 7.83452734e-08]\n",
            " [7.21566903e-05 9.99927640e-01 2.52561581e-08 2.44554013e-08\n",
            "  1.89964346e-08 1.73265313e-08 2.42583322e-08 2.41666154e-08\n",
            "  2.92261593e-08 2.07595807e-08 1.84324609e-08]\n",
            " [2.32832026e-05 9.99976754e-01 1.01303446e-08 9.75637171e-09\n",
            "  7.48782103e-09 6.63052768e-09 9.05514952e-09 9.05349218e-09\n",
            "  1.19662795e-08 7.87574894e-09 6.84547974e-09]\n",
            " [1.60735945e-05 9.99983907e-01 7.84173437e-09 7.48446194e-09\n",
            "  5.67411407e-09 5.04267827e-09 6.67577593e-09 6.69040956e-09\n",
            "  9.24874222e-09 5.92684302e-09 5.12722043e-09]\n",
            " [2.73798360e-05 9.99972582e-01 1.14818084e-08 1.10859890e-08\n",
            "  8.54079385e-09 7.57037633e-09 1.04319966e-08 1.04203419e-08\n",
            "  1.35470035e-08 9.01915609e-09 7.85932830e-09]\n",
            " [5.93310455e-04 9.99405742e-01 1.23591306e-07 1.15273842e-07\n",
            "  8.71968453e-08 9.07497864e-08 1.17455528e-07 1.18319171e-07\n",
            "  1.34746401e-07 1.05992683e-07 9.84707640e-08]\n",
            " [6.90564630e-05 9.99930739e-01 2.43702640e-08 2.36031763e-08\n",
            "  1.83354931e-08 1.66910272e-08 2.33766517e-08 2.32883117e-08\n",
            "  2.82340586e-08 1.99998009e-08 1.77412289e-08]\n",
            " [1.11051420e-04 9.99888539e-01 3.57003103e-08 3.44383793e-08\n",
            "  2.66934546e-08 2.48796592e-08 3.45805482e-08 3.44695934e-08\n",
            "  4.08099332e-08 2.97474223e-08 2.66630256e-08]]\n",
            "[1 1 1 1 1 1 1 1 1 1]\n",
            "[0.98968051 0.99651535]\n",
            "0.9930979324974568\n",
            "6    done\n",
            "Epoch 1/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.7502 - acc: 0.8756\n",
            "Epoch 2/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.2342 - acc: 0.9248\n",
            "Epoch 3/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.2192 - acc: 0.9380\n",
            "Epoch 4/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1877 - acc: 0.9500\n",
            "Epoch 5/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1876 - acc: 0.9428\n",
            "Epoch 6/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1858 - acc: 0.9436\n",
            "Epoch 7/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1664 - acc: 0.9476\n",
            "Epoch 8/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1829 - acc: 0.9432\n",
            "Epoch 9/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1824 - acc: 0.9448\n",
            "Epoch 10/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1781 - acc: 0.9408\n",
            "Epoch 11/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.2032 - acc: 0.9340\n",
            "Epoch 12/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1676 - acc: 0.9516\n",
            "Epoch 13/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1833 - acc: 0.9432\n",
            "Epoch 14/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1716 - acc: 0.9448\n",
            "Epoch 15/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1692 - acc: 0.9476\n",
            "Epoch 16/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1759 - acc: 0.9468\n",
            "Epoch 17/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1647 - acc: 0.9484\n",
            "Epoch 18/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1876 - acc: 0.9372\n",
            "Epoch 19/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1621 - acc: 0.9496\n",
            "Epoch 20/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1548 - acc: 0.9524\n",
            "Epoch 21/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1717 - acc: 0.9488\n",
            "Epoch 22/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1847 - acc: 0.9416\n",
            "Epoch 23/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1518 - acc: 0.9536\n",
            "Epoch 24/30\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.1664 - acc: 0.9496\n",
            "Epoch 25/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1645 - acc: 0.9480\n",
            "Epoch 26/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1685 - acc: 0.9448\n",
            "Epoch 27/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1698 - acc: 0.9448\n",
            "Epoch 28/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1895 - acc: 0.9428\n",
            "Epoch 29/30\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.1871 - acc: 0.9420\n",
            "Epoch 30/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1725 - acc: 0.9444\n",
            "[[4.88243240e-05 1.07273110e-03 4.14539641e-03 9.94732857e-01\n",
            "  2.63822972e-08 2.46737386e-08 2.79777908e-08 3.25695240e-08\n",
            "  3.16414912e-08 3.15504920e-08 3.49003741e-08]\n",
            " [9.30094975e-05 2.30665179e-03 2.13349480e-02 9.76265371e-01\n",
            "  1.00214570e-09 1.00133568e-09 1.73206105e-09 2.08467488e-09\n",
            "  1.35455380e-09 1.77776494e-09 2.18955121e-09]\n",
            " [3.06308095e-04 6.76920637e-03 2.24667817e-01 7.68256605e-01\n",
            "  6.37223468e-11 8.30242056e-11 1.83238161e-10 2.40131304e-10\n",
            "  9.83013115e-11 1.59667793e-10 2.23582486e-10]\n",
            " [5.18702036e-05 1.11998944e-03 3.08617949e-03 9.95741367e-01\n",
            "  9.22749592e-08 8.97842796e-08 8.52326991e-08 1.00621932e-07\n",
            "  1.07389894e-07 1.01232537e-07 1.08023663e-07]\n",
            " [5.74911319e-05 1.33967423e-03 7.12363329e-03 9.91479218e-01\n",
            "  7.16925008e-09 6.75410661e-09 9.14887455e-09 1.06186508e-08\n",
            "  8.93176022e-09 9.90288207e-09 1.13861311e-08]\n",
            " [2.57766398e-04 6.68577338e-03 1.45416046e-02 9.78512883e-01\n",
            "  2.34432875e-07 2.91324085e-07 2.54109494e-07 3.03526548e-07\n",
            "  2.68086126e-07 3.21892713e-07 3.19819009e-07]\n",
            " [1.31981302e-04 3.27765290e-03 6.95588905e-03 9.89632964e-01\n",
            "  1.85574294e-07 2.14785558e-07 1.85366630e-07 2.20984802e-07\n",
            "  2.11063565e-07 2.32372372e-07 2.38931989e-07]\n",
            " [4.81393799e-05 1.03418948e-03 3.28774750e-03 9.95629430e-01\n",
            "  5.66049714e-08 5.36368923e-08 5.46232677e-08 6.40799627e-08\n",
            "  6.66474875e-08 6.34300008e-08 6.86562984e-08]\n",
            " [1.15675866e-04 2.83045461e-03 6.05018577e-03 9.91002500e-01\n",
            "  1.78674171e-07 2.02917462e-07 1.75443361e-07 2.09102140e-07\n",
            "  2.03423184e-07 2.19137178e-07 2.26383747e-07]\n",
            " [2.20115107e-04 5.67902252e-03 1.21838115e-02 9.81915116e-01\n",
            "  2.19197645e-07 2.68982348e-07 2.33371395e-07 2.78536277e-07\n",
            "  2.49855532e-07 2.95188102e-07 2.96281826e-07]]\n",
            "[3 3 3 3 3 3 3 3 3 3]\n",
            "[0.90832491 0.96192114 0.97503593 0.98164668]\n",
            "0.9567321632385015\n",
            "7    done\n",
            "Epoch 1/30\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.9559 - acc: 0.6944\n",
            "Epoch 2/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1896 - acc: 0.9632\n",
            "Epoch 3/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1130 - acc: 0.9692\n",
            "Epoch 4/30\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.0957 - acc: 0.9648\n",
            "Epoch 5/30\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.0955 - acc: 0.9684\n",
            "Epoch 6/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0817 - acc: 0.9708\n",
            "Epoch 7/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0965 - acc: 0.9672\n",
            "Epoch 8/30\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.0955 - acc: 0.9652\n",
            "Epoch 9/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1114 - acc: 0.9656\n",
            "Epoch 10/30\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.0892 - acc: 0.9680\n",
            "Epoch 11/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0870 - acc: 0.9688\n",
            "Epoch 12/30\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.0877 - acc: 0.9704\n",
            "Epoch 13/30\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.0853 - acc: 0.9672\n",
            "Epoch 14/30\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.0839 - acc: 0.9712\n",
            "Epoch 15/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0923 - acc: 0.9636\n",
            "Epoch 16/30\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.0788 - acc: 0.9748\n",
            "Epoch 17/30\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.0716 - acc: 0.9760\n",
            "Epoch 18/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0868 - acc: 0.9692\n",
            "Epoch 19/30\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.0764 - acc: 0.9720\n",
            "Epoch 20/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0984 - acc: 0.9600\n",
            "Epoch 21/30\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.0827 - acc: 0.9708\n",
            "Epoch 22/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0799 - acc: 0.9700\n",
            "Epoch 23/30\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.0807 - acc: 0.9720\n",
            "Epoch 24/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0810 - acc: 0.9700\n",
            "Epoch 25/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0679 - acc: 0.9748\n",
            "Epoch 26/30\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.0959 - acc: 0.9652\n",
            "Epoch 27/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0781 - acc: 0.9708\n",
            "Epoch 28/30\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.0853 - acc: 0.9660\n",
            "Epoch 29/30\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0930 - acc: 0.9656\n",
            "Epoch 30/30\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.0986 - acc: 0.9592\n",
            "[[1.9457411e-06 6.0584915e-07 2.2267972e-07 5.5857663e-06 1.1537246e-03\n",
            "  9.9883181e-01 1.4268128e-06 9.4734014e-07 1.1515365e-06 1.4602754e-06\n",
            "  1.1554329e-06]\n",
            " [3.3221654e-06 7.6913165e-07 3.5035708e-07 1.1591682e-05 3.8457189e-03\n",
            "  9.9613094e-01 1.7385723e-06 1.1730741e-06 1.2519339e-06 1.5374368e-06\n",
            "  1.4884530e-06]\n",
            " [4.4325393e-06 1.1055287e-06 5.3687938e-07 1.8684321e-05 7.5770156e-03\n",
            "  9.9239033e-01 1.9685824e-06 1.3190725e-06 1.3279457e-06 1.6358174e-06\n",
            "  1.6737396e-06]\n",
            " [2.6815696e-06 6.3014545e-07 2.7042989e-07 8.3918167e-06 2.3550736e-03\n",
            "  9.9762625e-01 1.5829078e-06 1.0675777e-06 1.1950078e-06 1.4736689e-06\n",
            "  1.3462488e-06]\n",
            " [9.5136820e-06 3.6662561e-06 2.1046874e-06 7.8357007e-05 5.1232837e-02\n",
            "  9.4866347e-01 2.7201377e-06 1.7369312e-06 1.5272667e-06 1.9381412e-06\n",
            "  2.1525038e-06]\n",
            " [1.0000553e-05 3.9966390e-06 2.3255120e-06 8.6928208e-05 5.8648717e-02\n",
            "  9.4123775e-01 2.7792523e-06 1.7663527e-06 1.5406918e-06 1.9600375e-06\n",
            "  2.1834999e-06]\n",
            " [2.4834706e-06 6.0082226e-07 2.5108369e-07 7.5406333e-06 1.9816691e-03\n",
            "  9.9800092e-01 1.5322925e-06 1.0316347e-06 1.1763068e-06 1.4558055e-06\n",
            "  1.2953241e-06]\n",
            " [2.5140846e-06 6.0474503e-07 2.5386484e-07 7.6677325e-06 2.0368216e-03\n",
            "  9.9794561e-01 1.5400994e-06 1.0372509e-06 1.1791561e-06 1.4583635e-06\n",
            "  1.3034032e-06]\n",
            " [1.8487633e-06 6.4562494e-07 2.2647492e-07 5.2863220e-06 1.0276616e-03\n",
            "  9.9895811e-01 1.4377821e-06 9.4960109e-07 1.1685185e-06 1.4963149e-06\n",
            "  1.1436704e-06]\n",
            " [2.3518164e-06 5.8713044e-07 2.4013542e-07 7.0130754e-06 1.7548775e-03\n",
            "  9.9822849e-01 1.4992142e-06 1.0074621e-06 1.1645511e-06 1.4462338e-06\n",
            "  1.2598694e-06]]\n",
            "[5 5 5 5 5 5 5 5 5 5]\n",
            "[0.92462312 0.95586207 0.96583771 0.97115434 0.97450605 0.97740992]\n",
            "0.9615655334090686\n",
            "8    done\n",
            "Epoch 1/2\n",
            "80000/80000 [==============================] - 561s 7ms/step - loss: 0.3395 - acc: 0.8667\n",
            "Epoch 2/2\n",
            "80000/80000 [==============================] - 562s 7ms/step - loss: 0.3216 - acc: 0.8719\n",
            "[[9.0352742e-10 4.8899814e-08 6.0986132e-08 1.0395506e-06 3.4109980e-06\n",
            "  2.5784445e-06 2.9472803e-08 3.9583458e-07 5.9860282e-05 2.0943066e-02\n",
            "  9.7898942e-01]\n",
            " [1.1338744e-09 5.0496748e-08 2.8666310e-07 3.1334478e-06 9.0857320e-06\n",
            "  1.0965621e-05 1.7194661e-07 2.1821129e-06 4.0525492e-04 1.5804289e-01\n",
            "  8.4152597e-01]\n",
            " [9.6382302e-10 5.1251323e-08 8.5249468e-08 1.3211437e-06 4.2348265e-06\n",
            "  3.5279620e-06 4.2991321e-08 5.7122253e-07 8.9981186e-05 3.2326199e-02\n",
            "  9.6757400e-01]\n",
            " [9.4609365e-10 5.0682836e-08 7.7223447e-08 1.2306301e-06 3.9730344e-06\n",
            "  3.2159458e-06 3.8450167e-08 5.1256671e-07 7.9763849e-05 2.8437128e-02\n",
            "  9.7147399e-01]\n",
            " [7.6019985e-10 3.6826794e-08 2.7953524e-08 6.0757117e-07 2.0727762e-06\n",
            "  1.2531217e-06 1.2391107e-08 1.6935805e-07 2.3411541e-05 7.6327720e-03\n",
            "  9.9233961e-01]\n",
            " [9.0688079e-10 4.9063427e-08 6.2128542e-08 1.0533812e-06 3.4521552e-06\n",
            "  2.6235903e-06 3.0094387e-08 4.0395386e-07 6.1224426e-05 2.1452704e-02\n",
            "  9.7847843e-01]\n",
            " [1.1279914e-09 5.1208055e-08 2.5907224e-07 2.9212888e-06 8.5489846e-06\n",
            "  9.9785184e-06 1.5285978e-07 1.9481388e-06 3.5623153e-04 1.3811035e-01\n",
            "  8.6150962e-01]\n",
            " [6.0798150e-10 2.0101581e-08 7.7243567e-07 5.1228199e-06 1.3092550e-05\n",
            "  2.7191023e-05 6.3905395e-07 7.6320403e-06 1.8846296e-03 7.3952711e-01\n",
            "  2.5853381e-01]\n",
            " [1.1144515e-09 5.1978425e-08 2.2315524e-07 2.6311911e-06 7.8028188e-06\n",
            "  8.6812706e-06 1.2864072e-07 1.6494868e-06 2.9506162e-04 1.1336360e-01\n",
            "  8.8632023e-01]\n",
            " [2.9489400e-10 8.8850207e-09 7.4845286e-07 4.1192948e-06 1.0390332e-05\n",
            "  2.6664700e-05 7.5808680e-07 8.9962605e-06 2.5884607e-03 9.0820301e-01\n",
            "  8.9156941e-02]]\n",
            "[10 10 10 10 10 10 10 10 10 10]\n",
            "[0.         0.74015748 0.82806574 0.82142217 0.86833256 0.87073905\n",
            " 0.87099987 0.86983382 0.85936343 0.81024485]\n",
            "0.7539158962345804\n",
            "9    done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTQcQZIUZ3wl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model_ref = [1,3,5,1,2,9,5,9,1,3,1,1,1,1,1,1,1,1,1,1]\n",
        "y_pred_all = np.zeros((2000000))\n",
        "for pec in range(20):\n",
        "  x_test = test_signal.flatten()[pec*100000:(pec+1)*100000]\n",
        "  test_pred = models[model_ref[pec]].predict(x_test)\n",
        "  y_pred_1 = np.zeros(x_test.shape[0])\n",
        "  for j in range(test_pred.shape[0]):\n",
        "      maxval = 0\n",
        "      index = 0\n",
        "      for i in range(11):\n",
        "          if(test_pred[j][i] > maxval):\n",
        "              maxval = test_pred[j][i]\n",
        "              index = i\n",
        "      y_pred_1[j] = index\n",
        "  y_pred_all[pec*100000:(pec+1)*100000] = y_pred_1\n",
        "\n",
        "y_pred_all = np.array(y_pred_all).astype(int)\n",
        "\n",
        "# from numpy import asarray\n",
        "# from numpy import savetxt\n",
        "# savetxt(data_path + 'my_sub.csv', y_pred_1, fmt='%i', delimiter=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dwvnv9lTACJ7",
        "colab_type": "code",
        "outputId": "eba2036f-2e9c-4fc0-cff4-8d543edda1eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# model_spec = tf.keras.models.Sequential([\n",
        "#     tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "#                         input_shape=[None]),\n",
        "#       tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
        "#     tf.keras.layers.Dense(11,activation = 'softmax')\n",
        "#   ])\n",
        "\n",
        "# model_spec.compile(loss='sparse_categorical_crossentropy',\n",
        "#               optimizer='adam',\n",
        "#               metrics=['acc'])\n",
        "\n",
        "ranges = [4,9]\n",
        "for k in ranges:\n",
        "\n",
        "  # x_spec = train_signal[0].flatten()[:10000]\n",
        "  # y_spec = train_channels[0].flatten()[:10000]\n",
        "\n",
        "  # model_spec.fit(x = x_spec,y=y_spec, batch_size = batch_size, shuffle = True, epochs = 5)\n",
        "  # x = train_signal[k].flatten()\n",
        "  # y = train_channels[k].flatten()\n",
        "  valid_x = valid_signal[k].flatten()\n",
        "  valid_y = valid_channels[k].flatten()\n",
        "\n",
        "  \n",
        "  # model_spec.fit(x = x,y=y, batch_size = batch_size, shuffle = True, epochs = 1)\n",
        "  \n",
        "  y_pred = models[4].predict(valid_x)\n",
        "  y_true = np.array(valid_y).astype(int)\n",
        "  print(y_pred[:10])\n",
        "  print(y_true[:10])\n",
        "  y_pred_1 = np.zeros(y_true.shape)\n",
        "  y_pred_3 = models[2].predict(valid_x)\n",
        "  y_pred_1_3 = np.zeros(y_true.shape)\n",
        "\n",
        "  for j in range(y_pred_3.shape[0]):\n",
        "      \n",
        "      maxval = 0\n",
        "      index = 0\n",
        "      for i in range(11):\n",
        "          if(y_pred_3[j][i] > maxval):\n",
        "              maxval = y_pred_3[j][i]\n",
        "              index = i\n",
        "      y_pred_1_3[j] = index\n",
        "\n",
        "  y_pred_1_3 = np.array(y_pred_1_3).astype(int)\n",
        "\n",
        "\n",
        "\n",
        "  for j in range(y_pred.shape[0]):\n",
        "      if(valid_x[j]<-2):\n",
        "        y_pred_1[j] = y_pred_1_3[j]\n",
        "        continue\n",
        "      maxval = 0\n",
        "      index = 0\n",
        "      for i in range(11):\n",
        "          if(y_pred[j][i] > maxval):\n",
        "              maxval = y_pred[j][i]\n",
        "              index = i\n",
        "      y_pred_1[j] = index\n",
        "\n",
        "  #print(y_true.shape)\n",
        "  y_pred_1 = np.array(y_pred_1).astype(int)\n",
        "  y_true = np.array(y_true).astype(int)\n",
        "  print(f1_score(y_true, y_pred_1, average=None))\n",
        "  print(f1_score(y_true, y_pred_1, average='macro'))\n",
        "  print(k,\"   done\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.3863498e-10 5.4909872e-08 4.0876455e-11 2.1733882e-08 3.1773880e-08\n",
            "  1.6233528e-06 1.6195967e-06 4.6280331e-07 9.2853579e-06 1.1044670e-02\n",
            "  9.8894227e-01]\n",
            " [5.2342808e-10 5.2049078e-08 9.8607504e-11 4.5929642e-08 7.8410956e-08\n",
            "  3.8350481e-06 3.8928533e-06 1.2796088e-06 3.1577812e-05 3.2036494e-02\n",
            "  9.6792275e-01]\n",
            " [3.1260416e-10 5.7655342e-08 3.2693202e-11 1.7868425e-08 2.5483491e-08\n",
            "  1.3150294e-06 1.2962306e-06 3.5745677e-07 6.8242193e-06 8.4170643e-03\n",
            "  9.9157310e-01]\n",
            " [4.1100864e-10 5.2466088e-08 6.2577776e-11 3.1312027e-08 4.8947634e-08\n",
            "  2.4511414e-06 2.4769263e-06 7.5708220e-07 1.6756119e-05 1.8506140e-02\n",
            "  9.8147124e-01]\n",
            " [1.7236941e-09 4.4582791e-08 1.3508311e-09 3.1070613e-07 8.8552468e-07\n",
            "  3.4116460e-05 3.4316490e-05 1.9169438e-05 1.0072633e-03 5.3515869e-01\n",
            "  4.6374518e-01]\n",
            " [1.7265590e-09 4.4145207e-08 1.3834817e-09 3.1440325e-07 8.9881752e-07\n",
            "  3.4471319e-05 3.4678327e-05 1.9518615e-05 1.0354926e-03 5.4514229e-01\n",
            "  4.5373228e-01]\n",
            " [1.2903619e-09 2.0517698e-08 7.4919146e-09 6.3846039e-07 1.8902783e-06\n",
            "  3.3864362e-05 3.1219515e-05 4.0767074e-05 5.0778938e-03 9.5356691e-01\n",
            "  4.1246753e-02]\n",
            " [1.2881189e-09 2.0393932e-08 7.8847116e-09 6.5880312e-07 1.9491640e-06\n",
            "  3.3589862e-05 3.0696359e-05 4.1462121e-05 5.3120381e-03 9.5634794e-01\n",
            "  3.8231514e-02]\n",
            " [3.7382275e-10 5.3257903e-08 5.1396637e-11 2.6474227e-08 4.0022535e-08\n",
            "  2.0232956e-06 2.0352595e-06 6.0301164e-07 1.2747649e-05 1.4580705e-02\n",
            "  9.8540175e-01]\n",
            " [1.4792121e-09 5.2574347e-08 7.1265155e-10 2.1305065e-07 5.4815973e-07\n",
            "  2.3148077e-05 2.3249515e-05 1.0962475e-05 4.5966438e-04 3.0011126e-01\n",
            "  6.9937086e-01]]\n",
            "[10 10 10 10  9 10  9  9 10  9]\n",
            "[0.         0.         0.         0.62966507 0.83098054 0.864568\n",
            " 0.87289786 0.87648659 0.87862031 0.87038988 0.85561088]\n",
            "0.6072017396997595\n",
            "4    done\n",
            "[[2.9112837e-10 6.5847679e-08 2.3354913e-11 1.3111689e-08 1.8456161e-08\n",
            "  9.6734414e-07 9.2506957e-07 2.4122170e-07 4.2854895e-06 5.5573992e-03\n",
            "  9.9443603e-01]\n",
            " [4.1902831e-10 5.2363863e-08 6.5024992e-11 3.2348240e-08 5.0918793e-08\n",
            "  2.5450211e-06 2.5735260e-06 7.9140966e-07 1.7674847e-05 1.9385511e-02\n",
            "  9.8059076e-01]\n",
            " [2.9941655e-10 6.0684592e-08 2.7883565e-11 1.5485236e-08 2.1845347e-08\n",
            "  1.1353544e-06 1.1057621e-06 2.9714474e-07 5.4804882e-06 6.9271382e-03\n",
            "  9.9306482e-01]\n",
            " [2.9607888e-10 6.2014855e-08 2.6412058e-11 1.4731617e-08 2.0740821e-08\n",
            "  1.0806401e-06 1.0472805e-06 2.7890547e-07 5.0849276e-06 6.4790328e-03\n",
            "  9.9351341e-01]\n",
            " [3.1837263e-10 9.3325660e-08 1.6703519e-11 8.8223189e-09 1.3350083e-08\n",
            "  7.1910210e-07 6.4095531e-07 1.5515440e-07 2.5719000e-06 3.4789285e-03\n",
            "  9.9651682e-01]\n",
            " [2.9135960e-10 6.5507358e-08 2.3574314e-11 1.3231026e-08 1.8619808e-08\n",
            "  9.7545978e-07 9.3388894e-07 2.4392196e-07 4.3419204e-06 5.6232349e-03\n",
            "  9.9437016e-01]\n",
            " [4.0076764e-10 5.2625737e-08 5.9474113e-11 2.9986730e-08 4.6456137e-08\n",
            "  2.3321752e-06 2.3543680e-06 7.1384466e-07 1.5611717e-05 1.7400863e-02\n",
            "  9.8257810e-01]\n",
            " [1.1899791e-09 5.4343239e-08 4.3407056e-10 1.5004163e-07 3.5074106e-07\n",
            "  1.5536043e-05 1.5638971e-05 6.6486605e-06 2.4068213e-04 1.7839941e-01\n",
            "  8.2132155e-01]\n",
            " [3.7782252e-10 5.3139690e-08 5.2589478e-11 2.6999214e-08 4.0967723e-08\n",
            "  2.0688362e-06 2.0823957e-06 6.1921781e-07 1.3159879e-05 1.4991813e-02\n",
            "  9.8499006e-01]\n",
            " [1.6793251e-09 4.7825864e-08 1.1098475e-09 2.7998354e-07 7.7614271e-07\n",
            "  3.0927135e-05 3.1077627e-05 1.6377244e-05 7.9811248e-04 4.5508623e-01\n",
            "  5.4403615e-01]]\n",
            "[10 10 10 10 10 10 10 10 10 10]\n",
            "[0.         0.         0.         0.65228645 0.83009034 0.86364857\n",
            " 0.8716965  0.87308965 0.87243824 0.86345658 0.85665841]\n",
            "0.6075786136545047\n",
            "9    done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubR5H59D9Kv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batches = [5,7]\n",
        "\n",
        "for pec in batches:\n",
        "  x_test = test_signal.flatten()[pec*100000:(pec+1)*100000]\n",
        "  test_pred = models[model_ref[3]].predict(x_test)\n",
        "  y_pred_1 = np.zeros(x_test.shape[0])\n",
        "  for j in range(test_pred.shape[0]):\n",
        "      if(x_test[j]>0):\n",
        "        y_pred_1[j] = y_pred_all[pec*100000 + j]\n",
        "        continue\n",
        "\n",
        "      maxval = 0\n",
        "      index = 0\n",
        "      for i in range(11):\n",
        "          if(test_pred[j][i] > maxval):\n",
        "              maxval = test_pred[j][i]\n",
        "              index = i\n",
        "      y_pred_1[j] = index\n",
        "  y_pred_all[pec*100000:(pec+1)*100000] = y_pred_1\n",
        "\n",
        "y_pred_all = np.array(y_pred_all).astype(int)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPTSMI4glSsr",
        "colab_type": "code",
        "outputId": "bd91fd87-3d80-4473-8caf-75af2de94d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "sub = pd.read_csv(data_path + 'sample_submission_ion.csv')\n",
        "\n",
        "sub.iloc[:,1] = y_pred_all\n",
        "sub.to_csv(data_path + 'my_submission_diffmo3.csv',index=False,float_format='%.4f')\n",
        "print(\"saved the file 3\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saved the file 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySxOhz9p9n29",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "64cccd64-c6bb-440d-eee5-96d247be8750"
      },
      "source": [
        "x_last = train_signal[9].flatten()\n",
        "y_last = train_channels[9].flatten()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1fb55d8b5fa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_signal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_signal' is not defined"
          ]
        }
      ]
    }
  ]
}